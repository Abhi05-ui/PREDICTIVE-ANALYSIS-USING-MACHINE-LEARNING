# PREDICTIVE-ANALYSIS-USING-MACHINE-LEARNING

COMPANY : CODTECH IT SOLUTIONS 

NAME : ABIRAMI S 

INTERN ID : CT04DL633 

DOMAIN : DATA ANALYTICS DURATION : 4 WEEKS

# DISCRIPTION :

This task demonstrates an analysis and prediction of AI-generated image engagement using the PySpark framework. The goal was to predict the number of likes based on various features and evaluate their importance using a Random Forest Regressor. The dataset used contains information such as generation time, GPU usage, file size, style accuracy score, and platform type.

Steps Completed
Data Loading and Preprocessing

Loaded the dataset into a PySpark DataFrame.

Handled missing values by dropping incomplete rows to ensure data consistency.

Encoded the categorical variable platform into numerical values using the StringIndexer.

Feature Selection and Vectorization

Selected relevant features: generation_time, gpu_usage, file_size_kb, style_accuracy_score, and the encoded platform_index.

Created a feature vector using VectorAssembler for efficient input into the Random Forest model.

Model Training and Evaluation

Split the dataset into training (80%) and testing (20%) sets to train the model and validate its performance.

Trained a Random Forest Regressor with 100 trees to predict the number of likes.

Evaluated the model using Root Mean Squared Error (RMSE), which was 1529.46.

Feature Importance Analysis

Extracted and visualized the importance of each feature in predicting engagement.

Found that style_accuracy_score and generation_time were the most significant predictors.

Visualization of Results

Plotted feature importance using Matplotlib to provide actionable insights on which attributes most influence engagement.

Key Insights from Output
RMSE Value: The modelâ€™s RMSE indicates the error margin for predictions, useful for further tuning.

Feature Importance:

style_accuracy_score and generation_time are crucial for predicting likes, providing potential areas to optimize for better engagement.

gpu_usage and file_size_kb hold moderate influence, while platform_index has comparatively less impact.

Tools and Libraries
PySpark for scalable data processing and machine learning.

Matplotlib for feature importance visualization.

Google Colab for interactive coding and visualization.

This task highlights the application of PySpark in big data analysis, focusing on interpretability and actionable insights. The interactive analysis was concluded with a clear visualization of feature importance to guide decisions.
#OUTPUT : 

![Image](https://github.com/user-attachments/assets/da6a5467-7532-45a2-a18b-2b090cbe560f)
